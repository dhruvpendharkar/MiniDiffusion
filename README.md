# MiniDiffusion
Building a small diffusion model and optimizing it for image generation and text-to-image

Motivation:
Diffusion is (arguably) an incredible process for generating images which has backed many of the most prominent image generation tools of the past few years. While I, and many others, lack the computational resources to train large scale diffusion models my objective is to build a small scale implementation and optimize it. To make this a useful tool I will emphasize working with images that have low feature density, meaning that training with smaller images won't significantly alter the quality of the outputs.

